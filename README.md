# fall-2025-patient-risk-identification
Team project: fall-2025-patient-risk-identification

# Project README

## 1. Project Overview

This project focuses on predicting 30-day readmissions for inpatient encounters using a comprehensive set of patient demographics, encounter-level features, and historical utilization data. The goal is to develop a predictive model that can identify patients at high risk of readmission, enabling proactive interventions and improving patient outcomes. The project explores both Logistic Regression and Random Forest classifiers, with a particular emphasis on hyperparameter tuning for the latter to optimize performance.

## 2. Data Sources

The analysis utilizes synthetic healthcare data generated by Synthea, provided in CSV format. The following modules were integrated:

*   **`encounters.csv`**: Core encounter information, filtered for inpatient stays.
*   **`patients.csv`**: Patient demographic data, including age, gender, race, and ethnicity.
*   **`observations.csv`**: Clinical observations (e.g., vital signs, lab results).
*   **`procedures.csv`**: Medical procedures performed during encounters.
*   **`conditions.csv`**: Patient diagnoses and health conditions.
*   **`immunizations.csv`**: Immunization records.
*   **`medications.csv`**: Medication prescriptions and administrations.

## 3. Methodology

### 3.1. Data Loading and Initial Filtering

All relevant CSV files were loaded into pandas DataFrames. Inpatient encounters were isolated from the `encounters.csv` dataset, and a left join was performed with `patients.csv` to enrich encounter records with demographic details.

### 3.2. Feature Engineering

Extensive feature engineering was performed, including:

*   **Encounter-level features**: Length of stay (`LOS_days`), admission hour (`admit_hour`), day of week (`admit_dow`), weekend/night admissions (`is_weekend`, `is_night`), and calendar context (`admit_month`, `admit_quarter`, `admit_season`).
*   **Readmission target**: A binary `READMIT_30D` flag indicating readmission within 30 days of discharge for inpatient encounters.
*   **Prior encounter gap**: Time since the last discharge (`gap_since_prev_discharge_days`).
*   **Rolling prior-year utilization**: Counts of total, ER, inpatient, and outpatient encounters in the past 365 days (`prior365_total_enc`, `prior365_ER`, `prior365_inpatient`, `prior365_outpatient`), along with mean LOS and total cost.
*   **Previous encounter class**: The type of the immediately preceding encounter (`prev_class`).
*   **Module-specific features**: Counts, binary flags, and proportions of categories for observations, procedures, conditions, immunizations (e.g., flu vaccine within 1 year), and medications (number active at admission).

### 3.3. Preprocessing for Modeling

*   **Missing Value Imputation**: Numerical columns were imputed with their median, and categorical columns with a 'Missing' category or False for booleans.
*   **Age Calculation**: Patient age was calculated from `BIRTHDATE`.
*   **Train/Test Split**: Data was split using `GroupShuffleSplit` (80% train, 20% test) to ensure that all encounters from a single patient appear in either the training or testing set, preventing data leakage across patients.
*   **Categorical Encoding**: One-hot encoding was applied to categorical features (`GENDER`, `RACE`, `ETHNICITY`).
*   **Feature Scaling**: Numerical features were scaled using `StandardScaler`.

### 3.4. Model Training and Evaluation

Two classification models were implemented and evaluated:

*   **Logistic Regression**: A baseline model trained with `class_weight='balanced'` to address class imbalance.
*   **Random Forest Classifier**: An ensemble model known for its robustness, also trained with `class_weight='balanced'`.

Both models were evaluated using 5-fold `GroupKFold` cross-validation. Key metrics included AUC, Precision, Recall, F1-score, and Accuracy, with a focus on the readmission (Class 1) metrics due to class imbalance.

### 3.5. Hyperparameter Tuning (Random Forest)

`GridSearchCV` was employed to fine-tune the Random Forest Classifier's hyperparameters using `GroupKFold` for robust evaluation. The parameter grid explored `n_estimators`, `max_depth`, `min_samples_split`, and `class_weight`. `roc_auc` was used as the primary refit metric.

## 4. Model Comparison: Random Forest vs. Logistic Regression

| Metric                | Logistic Regression | Random Forest (Untuned) |
|:----------------------|:--------------------|:------------------------|
| **Average AUC**       | 0.876               | 0.897                   |
| **Precision (Class 1)** | 0.450               | 0.457                   |
| **Recall (Class 1)**    | 0.857               | 0.909                   |
| **F1-score (Class 1)**  | 0.590               | 0.607                   |
| **Accuracy**          | 0.809               | 0.812                   |

The Random Forest model generally performed better than Logistic Regression, exhibiting a higher AUC and significantly improved recall for identifying readmission cases.

## 5. Tuned Random Forest Model Summary

After hyperparameter tuning, the best Random Forest model achieved the following:

*   **Best Hyperparameters**: `n_estimators=200`, `max_depth=None`, `min_samples_split=10`, `class_weight='balanced'`.
*   **Performance on Test Set**:
    *   **AUC Score**: `0.993`
    *   **Precision (Class 1 - Readmission)**: `0.771`
    *   **Recall (Class 1 - Readmission)**: `0.966`
    *   **F1-score (Class 1 - Readmission)**: `0.858`
    *   **Overall Accuracy**: `0.947`

The tuning process dramatically improved the model's performance, particularly in precision for the positive class, while maintaining high recall.

## 6. Key Findings and Conclusions

*   The tuned Random Forest Classifier demonstrates excellent capability in predicting 30-day readmissions, with an AUC of 0.993 and strong recall (0.966) for the readmission class.
*   **Feature Importance Analysis** revealed `prior365_total_enc` (total encounters in the past year) as the most influential predictor, indicating that patients with higher recent healthcare utilization are significantly more likely to be readmitted. Other significant features included various procedure and observation categorical counts, and demographic factors like `AGE` and `GENDER`.
*   The project successfully leveraged a variety of Synthea-generated features to build a robust predictive model. The high recall suggests the model is effective at identifying high-risk patients, which is critical for clinical decision-making.
*   The improved precision of the tuned Random Forest model (0.771) indicates a significant reduction in false positives compared to the untuned models, making it more reliable for actionable interventions.

### Next Steps

*   Further exploration of feature interactions and non-linear relationships. 
